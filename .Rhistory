#testingHAR<-testingHAR[,-nsv]
#testingHAR<-testingHAR[,7:d[2]]
#validationHAR<-validationHAR[,-nsv]
#validationHAR<-validationHAR[,7:d[2]]
set.seed(125)
modFit <- train(classe ~ ., method="gbm",data=trainingHAR,verbose=FALSE,allowParallel=TRUE)
doMC::registerDoMC(cores=4)
modFit <- train(classe ~ ., method="gbm",data=trainingHAR,verbose=FALSE,allowParallel=TRUE)
library(caret)
library(ISLR); library(ggplot2);
# Create 1 datasets reading the CSV file
# We will Use this dataset both for training(60%) testing(20%) and Validation (20%) purpose.
#
inDatasetHAR<-read.csv(file="pml-training.csv",head=TRUE,sep=",")
inDatasetValidHAR<-read.csv(file="pml-testing.csv",head=TRUE,sep=",")
inDatasetRefHAR<-read.csv(file="dataset-har.csv",head=TRUE,sep=";")
inTrainTest <- createDataPartition(y=inDatasetHAR$classe,p=0.8, list=FALSE)
#80% of data for training and tests
trainingAndTestHAR <- inDatasetHAR[inTrainTest,]
#Now Split in training and testing dataset (75% 25%)
TrTeHAR<-createDataPartition(y=trainingAndTestHAR$classe,p=0.75, list=FALSE)
trainingHAR<-trainingAndTestHAR[TrTeHAR,]
testingHAR<-trainingAndTestHAR[-TrTeHAR,]
#20% of original data for validation
validationHAR <- inDatasetHAR[-inTrainTest,]
# Analysis of training dataset : a lot of variable without values, maybe correlated and without variance
#
nsv<-nearZeroVar(trainingHAR,saveMetrics=F)
trainingHAR<- trainingHAR[, -nsv]
d<-dim(trainingHAR)
trainingHAR<-trainingHAR[,7:d[2]]
testingHAR<-testingHAR[,-nsv]
testingHAR<-testingHAR[,7:d[2]]
validationHAR<-validationHAR[,-nsv]
validationHAR<-validationHAR[,7:d[2]]
set.seed(125)
doMC::registerDoMC(cores=4)
rf<-train(outcome ~ ., data=trainingHAR, method="rf", prox=TRUE, ntree=500,do.trace=TRUE)
rf<-train(classe ~ ., data=trainingHAR, method="rf", prox=TRUE, ntree=500,do.trace=TRUE)
prox = rf$finalModel$prox
prox
View(prox)
head(getTree(modFit$finalModel,k=2))
head(getTree(rf$finalModel,k=2))
head(getTree(rf$finalModel,k=200))
head(getTree(rf$finalModel,k=500))
head(getTree(rf$finalModel,k=501))
head(getTree(rf$finalModel,k=400))
lda <- train(classe ~ .,data=trainingHRE,method="lda")
lda <- train(classe ~ .,data=trainingHAR,method="lda")
lda
keep.dat<-vif_func(in_frame=trainingHAR,thresh=5,trace=F)
library(MASS)
keep.dat<-vif_func(in_frame=trainingHAR,thresh=5,trace=F)
library(clustergeneration)
install.packages("clusterGeneration")
library(clustergeneration)
library(clusterGeneration)
keep.dat<-vif_func(in_frame=trainingHAR,thresh=5,trace=F)
install.packages("VIF")
keep.dat<-vif_func(in_frame=trainingHAR,thresh=5,trace=F)
library(VIF)
keep.dat<-vif_func(in_frame=trainingHAR,thresh=5,trace=F)
#stepwise VIF function used below
vif_func<-function(in_frame,thresh=10,trace=T,...){
require(fmsb)
if(class(in_frame) != 'data.frame') in_frame<-data.frame(in_frame)
#get initial vif value for all comparisons of variables
vif_init<-NULL
for(val in names(in_frame)){
form_in<-formula(paste(val,' ~ .'))
vif_init<-rbind(vif_init,c(val,VIF(lm(form_in,data=in_frame,...))))
}
vif_max<-max(as.numeric(vif_init[,2]))
if(vif_max < thresh){
if(trace==T){ #print output of each iteration
prmatrix(vif_init,collab=c('var','vif'),rowlab=rep('',nrow(vif_init)),quote=F)
cat('\n')
cat(paste('All variables have VIF < ', thresh,', max VIF ',round(vif_max,2), sep=''),'\n\n')
}
return(names(in_frame))
}
else{
in_dat<-in_frame
#backwards selection of explanatory variables, stops when all VIF values are below 'thresh'
while(vif_max >= thresh){
vif_vals<-NULL
for(val in names(in_dat)){
form_in<-formula(paste(val,' ~ .'))
vif_add<-VIF(lm(form_in,data=in_dat,...))
vif_vals<-rbind(vif_vals,c(val,vif_add))
}
max_row<-which(vif_vals[,2] == max(as.numeric(vif_vals[,2])))[1]
vif_max<-as.numeric(vif_vals[max_row,2])
if(vif_max<thresh) break
if(trace==T){ #print output of each iteration
prmatrix(vif_vals,collab=c('var','vif'),rowlab=rep('',nrow(vif_vals)),quote=F)
cat('\n')
cat('removed: ',vif_vals[max_row,1],vif_max,'\n\n')
flush.console()
}
in_dat<-in_dat[,!names(in_dat) %in% vif_vals[max_row,1]]
}
return(names(in_dat))
}
}
keep.dat<-vif_func(in_frame=trainingHAR,thresh=5,trace=F)
install.packages("fmsb")
keep.dat<-vif_func(in_frame=trainingHAR,thresh=5,trace=F)
inVarImp <- createDataPartition(y = trainingHAR$classe, p = 0.1, list = F)
varImpSub <- trainingHAR[inVarImp, ]
varImpRF <- train(classe ~ ., data = varImpSub, method = "rf")
varImpObj <- varImp(varImpRF)
plot(varImpObj, main = "Variable Importance of Top 52", top = 52)
plot(varImpObj, main = "Variable Importance of Top 20", top = 20)
finalTraingData <- trainingHAR[-inVarImp, ]
impThresh <- quantile(varImpObj$importance[, 1], 0.75)
impfilter <- varImpObj$importance[, 1] >= impThresh
finalTraingData <- finalTraingData[, impfilter]
rfModel <- train(classe ~ ., data = finalTraingData, method = "rf")
View(finalTraingData)
varImpObj
varImpObj[1]
varImpObj[2]
varImpObj[3]
rfModel <- train(classe ~ varImpObj, data = trainingHAR, method = "rf")
rfModel <- train(classe ~ varImpObj[1], data = trainingHAR, method = "rf")
View(inVarImp)
trainingHAR[1,inVarImp(1)]
trainingHAR[1,inVarImp[1]]
trainingHAR[,inVarImp[1]]
trainingHAR[,inVarImpObj[1]]
trainingHAR[,c(inVarImpObj[1])]
dim(finalTraingData)
varImpObj$importance[, 1]
varImpObj$importance[,]
varImpObj$importance[1,]
varImpObj$importance[1,1]
varImpObj$importance[,1]
varImpObj
rfModel <- train(classe ~ min_pitch_arm+pitch_belt, data = trainingHAR, method = "rf")
predict(modFit, testingHAR)
predict(rfModel, testingHAR)
rfModel <- train(classe ~ min_pitch_arm+pitch_belt+accel_forearm_x, data = trainingHAR, method = "rf")
predict(rfModel, testingHAR)
rfModel <- train(classe ~ min_pitch_arm+pitch_belt+accel_forearm_x+gyros_dumbbell_x, data = trainingHAR, method = "rf")
predict(rfModel, testingHAR)
rfModel <- train(classe ~ min_pitch_arm+pitch_belt+accel_forearm_x+gyros_dumbbell_x+accel_belt_x, data = trainingHAR, method = "rf")
predict(rfModel, testingHAR)
rfModel <- train(classe ~ min_pitch_arm+pitch_belt+accel_forearm_x+gyros_dumbbell_x+accel_belt_x+stddev_pitch_dumbbell, data = trainingHAR, method = "rf")
predict(rfModel, testingHAR)
modFit <- train(classe ~ ., method="gbm",data=trainingHAR,verbose=FALSE,allowParallel=TRUE)
library(caret)
library(ISLR); library(ggplot2);
# Create 1 datasets reading the CSV file
# We will Use this dataset both for training(60%) testing(20%) and Validation (20%) purpose.
#
inDatasetHAR<-read.csv(file="pml-training.csv",head=TRUE,sep=",")
inDatasetValidHAR<-read.csv(file="pml-testing.csv",head=TRUE,sep=",")
inDatasetRefHAR<-read.csv(file="dataset-har.csv",head=TRUE,sep=";")
inTrainTest <- createDataPartition(y=inDatasetHAR$classe,p=0.8, list=FALSE)
#80% of data for training and tests
trainingAndTestHAR <- inDatasetHAR[inTrainTest,]
#Now Split in training and testing dataset (75% 25%)
TrTeHAR<-createDataPartition(y=trainingAndTestHAR$classe,p=0.75, list=FALSE)
trainingHAR<-trainingAndTestHAR[TrTeHAR,]
testingHAR<-trainingAndTestHAR[-TrTeHAR,]
#20% of original data for validation
validationHAR <- inDatasetHAR[-inTrainTest,]
# Analysis of training dataset : a lot of variable without values, maybe correlated and without variance
#
nsv<-nearZeroVar(trainingHAR,saveMetrics=F)
trainingHAR<- trainingHAR[, -nsv]
d<-dim(trainingHAR)
trainingHAR<-trainingHAR[,7:d[2]]
testingHAR<-testingHAR[,-nsv]
testingHAR<-testingHAR[,7:d[2]]
validationHAR<-validationHAR[,-nsv]
validationHAR<-validationHAR[,7:d[2]]
set.seed(125)
doMC::registerDoMC(cores=4)
modFit <- train(classe ~ ., method="gbm",data=trainingHAR,verbose=FALSE,allowParallel=TRUE)
View(trainingHAR)
outlierTest(trainingHAR)
library(car)
install.packages("car")
library(car)
outlierTest(trainingHAR)
outlierTest(modFit)
lda <- train(classe ~ .,data=trainingHAR,method="lda")
outlierTest(lda)
qqPlot(lda, main="QQ Plot")
qqPlot(lda, main="QQ Plot")
qr(trainingHAR)$pivot
lm <- train(y ~ ., method="lm", data=trainingHAR)
lm <- train(classe ~ ., method="lm", data=trainingHAR)
plot(lda$finalModel)
plot(lda$finalModel)
nearZeroVar(trainingHAR,saveMetrics=F)
nearZeroVar(trainingHAR,saveMetrics=T)
trainknn<-preProcess(trainingHAR, method="knnImpute")
trainknn<-trainingHAR
trainknn[1]<-preProcess(trainingHAR[1], method="knnImpute")
trainknn[,1]<-preProcess(trainingHAR[,1], method="knnImpute")
View(trainknn)
trainknn[,5]<-preProcess(trainingHAR[,5], method="knnImpute")
preProcess(trainingHAR[,5], method="knnImpute")
selectNA <- rbinom(dim(trainingHAR)[1],size=1,prob=0.05)==1
preProcess(trainingHAR[,-58], method="knnImpute")
trainknn<-trainingHAR[,5:6]
preProcess(trainknn[,-58], method="knnImpute")
train2<-preProcess(trainknn[,-58], method="knnImpute")
train2
train2[1,]
train2[1]
testCapAveS <- (trainingHAR - mean(trainingHAR)) / sd(trainingHAR)
variable.sparseness <- apply(trainingHAR, 2, sparseness)
n
sparseness <- function(a) {
n <- length(a)
na.count <- sum(is.na(a))
return((n - na.count)/n)
}
variable.sparseness <- apply(trainingHAR, 2, sparseness)
trimTrainSub <- trainingHAR[, variable.sparseness > 0.9]
View(trimTrainSub)
modFit <- train(classe ~ ., method="gbm",data=trimTrainSub,verbose=FALSE,allowParallel=TRUE)
View(trimTrainSub)
modFit <- train(classe ~ ., method="rf",data=trimTrainSub,verbose=FALSE,allowParallel=TRUE)
print(modFit)
confusionMatrix(testingHAR$classe, predict(modFit, testingHAR))
resu<-confusionMatrix(testingHAR$classe, predict(modFit, testingHAR))
plot(resu)
resu
resu<-confusion(testingHAR$classe, predict(modFit, testingHAR))
resu.table
as.table(resu)
plot(as.table(resu))
ggplot(as.table(resu))
ggplot(as.data.frame(as.table(resu)))
normalize()
z<-as.table(resu)
colnames(z) = c("A","B","C","D","E")
rownames(z)=colnames(z)
image(z[,ncol(z):1], axes=FALSE)
heatmap(t(z)[ncol(z):1,], Rowv=NA,
Colv=NA, col = heat.colors(256))
plt.matshow(z)
heatmap(t(z)[ncol(z):1,], Rowv=NA,
Colv=NA, col = heat.colors(256))
heatmap(t(z)[ncol(z):1,], Rowv=NA,
Colv=NA, col = heat.colors(1256))
heatmap(t(z)[ncol(z):1,], Rowv=NA,
Colv=NA, col = heat.colors(64))
heatmap(t(z)[ncol(z):1,], Rowv=NA,
Colv=NA, col = heat.colors(64))
image(z[,ncol(z):1], axes=FALSE)
resuVAL<-confusion(validationHAR$classe, predict(modFit, validationHAR))
resuVAL<-confusionmatrix(validationHAR$classe, predict(modFit, validationHAR))
resuVAL<-confusionMatrix(validationHAR$classe, predict(modFit, validationHAR))
resuVAL
zval<-as.table(resuVAL)
zval
resuVAL<-confusionMatrix(inDatasetRefHAR$classe, predict(modFit, inDatasetRefHAR))
resuVAL<-confusionMatrix(inDatasetValidHAR$classe, predict(modFit, inDatasetValidHAR))
plot(density(trainingHAR$classe, col="blue")
)
nsv<-nearZeroVar(trainingHAR,saveMetrics=F)
nsv
nsv<-nearZeroVar(trainingHAR,saveMetrics=T)
nsv
library(caret)
library(ISLR); library(ggplot2);
# Create 1 datasets reading the CSV file
# We will Use this dataset both for training(70%) and testing(30%) purpose.
#
inDatasetHAR<-read.csv(file="pml-training.csv",head=TRUE,sep=",")
inDatasetValidHAR<-read.csv(file="pml-testing.csv",head=TRUE,sep=",")
#
#This is the data file that Velloso, E.; Bulling, A.; Gellersen, H.;
#Ugulino, W.; Fuks, H. use in thei paper "Qualitative Activity Recognition of
# Weight Lifting Exercises. Proceedings of 4th International Conference in
#Cooperation with SIGCHI (Augmented Human '13) .
##Stuttgart, Germany: ACM SIGCHI, 2013.
#
##Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3mvTxcXYG
#inDatasetRefHAR<-read.csv(file="dataset-har.csv",head=TRUE,sep=";")
#
#
#
inTrainTest <- createDataPartition(y=inDatasetHAR$classe,p=0.7, list=FALSE)
#70% of data for training and tests
TrTeHAR <- inDatasetHAR[inTrainTest,]
#Now Split in training and testing dataset (70% 30%)
trainingHAR<-inDatasetHAR[TrTeHAR,]
testingHAR<-inDatasetHAR[-TrTeHAR,]
trainingHAR<-inDatasetHAR[inTrainTest,]
testingHAR<-inDatasetHAR[-inTrainTest,]
##
## DATA ANALYSIS
##
# Analysis of training dataset : a lot of variable with "MISSING values", correlated and without variance
#
nsv<-nearZeroVar(trainingHAR,saveMetrics=T)
nsv
nsv(4)
nsv
nsv[4]
View(testingHAR)
View(trainingHAR)
nsv
trainingHAR<- trainingHAR[, -nsv]
nsv
nzv <- nearZeroVar(trainingHAR)
filteredDescr <- mdrrDescr[, -nzv]
dim(filteredDescr)
nzv <- nearZeroVar(trainingHAR)
filteredDescr <- trainingHAR[, -nzv]
dim(filteredDescr)
View(filteredDescr)
descrCor <-  cor(filteredDescr)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
nsv2<-nearZeroVar(filteredDescr,saveMetrics=T)
nsv2
library(caret)
library(ISLR); library(ggplot2);
# Create 1 datasets reading the CSV file
# We will Use this dataset both for training(70%) and testing(30%) purpose.
#
inDatasetHAR<-read.csv(file="pml-training.csv",head=TRUE,sep=",")
inDatasetValidHAR<-read.csv(file="pml-testing.csv",head=TRUE,sep=",")
#
#This is the data file that Velloso, E.; Bulling, A.; Gellersen, H.;
#Ugulino, W.; Fuks, H. use in thei paper "Qualitative Activity Recognition of
# Weight Lifting Exercises. Proceedings of 4th International Conference in
#Cooperation with SIGCHI (Augmented Human '13) .
##Stuttgart, Germany: ACM SIGCHI, 2013.
#
##Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3mvTxcXYG
#inDatasetRefHAR<-read.csv(file="dataset-har.csv",head=TRUE,sep=";")
#
#
#
inTrainTest <- createDataPartition(y=inDatasetHAR$classe,p=0.7, list=FALSE)
#70% of data for training and tests
#Now Split in training and testing dataset (70% 30%)
trainingHAR<-inDatasetHAR[inTrainTest,]
testingHAR<-inDatasetHAR[-inTrainTest,]
##
## DATA ANALYSIS
##
#
# First 7 columns of the datasets can be skipped as they are not relevant for the analysis (name, window, ID...)
#
d<-dim(trainingHAR)
trainingHAR<-trainingHAR[,8:d[2]]
testingHAR<-testingHAR[,8:d[2]]
#
# Analysis of training dataset : a lot of variable with "MISSING values", correlated and without variance
#
#
#
#
#
nsv<-nearZeroVar(trainingHAR)
trainingHAR<- trainingHAR[, -nsv]
testingHAR<-testingHAR[,-nsv]
View(testingHAR)
nsv2<-nearZeroVar(trainingHAR,saveMetrics=T)
nsv2
is.na(traininhHAR)
is.na(trainingHAR)
listNA<-is.na(trainingHAR)
hist(listNA)
nsv2<-nearZeroVar(trainingHAR,saveMetrics=T)
nsv2
nsv2[2]
nsv2[2]>=5
sparseness <- function(a) {
n <- length(a)
na.count <- sum(is.na(a))
return((n - na.count)/n)
}
# sparness of input variables based on training subset
variable.sparseness <- apply(trainingHAR, 2, sparseness)
variable.sparseness
variable.sparseness[2]>0.9
variable.sparseness[2]
variable.sparseness>0.9
dim (variable)
View(testingHAR)
variable.sparseness>0.9
nsv2[2]>=2
nsv2[2]>=2==TRUE
print(nsv2,nsv2[2]>=2)
print(nsv2,freqRatio>=2)
print(nsv2,nsv2.freqRatio>=2)
print(nsv2[2]>=2)
print(nsv2[1])
nsv
print(nsv2[2]>=2)
variable.sparseness>0.9
c(nsv2[2])
c(nsv2[1])
c(nsv2)
c(nsv2==TRUE)
nsv2
checkConditionalX(trainingHAR, na)
checkConditionalX(trainingHAR, "NA")
l<-checkConditionalX(trainingHAR, "NA")
l
l<-trainingHAR[-c(nsv2[2]>2)]
l<-trainingHAR[-nsv2[2]>2]
l<-trainingHAR[-c(nsv2[2]>2)]
l<-trainingHAR[,-c(nsv2[2]>2)]
nsv2
nsv2$freqRatio>2
l<-trainingHAR[,-c(nsv2$freqRatio>2)]
l1<-trainingHAR[,-c(nsv2$freqRatio>2)]
View(l)
indexc<-c(nsv2$freqRatio>2)
indexc
c(indexc)
l1<-trainingHAR[,indexc]
l2<-trainingHAR[,-indexc]
-indexc
l2<-trainingHAR[,!indexc]
modFit <- train(classe ~ ., method="rf",data=l2,verbose=FALSE,allowParallel=TRUE)
print(modFit)
trimTrainSub <- trainingHAR[, variable.sparseness > 0.9]
modFit <- train(classe ~ ., method="rf",data=trimTrainSub,verbose=FALSE,allowParallel=TRUE)
print(modFit)
na_count <-sapply(trainingHAR, function(y) sum(length(which(is.na(y)))))
na_count
na_perc=na_count/dim(trainingHAR)
l2<- trainingHAR[, na_perc > 0.9]
modFit <- train(classe ~ ., method="rf",data=l2,verbose=FALSE,allowParallel=TRUE)
l2<- trainingHAR[, na_perc <= 0.9]
modFit <- train(classe ~ ., method="rf",data=l2,verbose=FALSE,allowParallel=TRUE)
print(modFit)
resu<-confusionMatrix(testingHAR$classe, predict(modFit, testingHAR))
resu
z<-as.table(resu)
colnames(z) = c("A","B","C","D","E")
rownames(z)=colnames(z)
image(z[,ncol(z):1], axes=FALSE)
heatmap(t(z)[ncol(z):1,], Rowv=NA,
+         Colv=NA, col = heat.colors(256))
image(z[,ncol(z):1], axes=FALSE)
heatmap(t(z)[ncol(z):1,], Rowv=NA,
+         Colv=NA, col = heat.colors(256))
heatmap(t(z)[ncol(z):1,], Rowv=NA,Colv=NA, col = heat.colors(256))
as.table(resu)
library(PerformanceAnalytics)
mydata <- mtcars[, c(1,3,4,5,6,7)]
chart.Correlation(mydata, histogram=TRUE, pch=19)
library(PerformanceAnalytics)
mydata <- trainingHAR[, c(8:20)]
chart.Correlation(mydata, histogram=TRUE, pch=19)
library(PerformanceAnalytics)
mydata <- trainingHAR[, c(8:20)]
chart.Correlation(mydata, histogram=TRUE, pch=19)
result <- rfcv(trainingHAR[,1:dim(trainingHAR)-1],trainingHAR[,dim(trainingHAR)],cv.fold=5,mtry=function(p) max(1, floor(sqrt(p))), recursive=TRUE)
dim(trainingHAR)
result <- rfcv(trainingHAR[,8:100],trainingHAR[,101],cv.fold=5,mtry=function(p) max(1, floor(sqrt(p))), recursive=TRUE)
na_count <-sapply(trainingHAR, function(y) sum(length(which(is.na(y)))))
na_perc=na_count/dim(trainingHAR)
reducedTrainingHAR<-trainingHAR[, na_perc <= 0.9]
reducedTestingHAR<-testingHAR[, na_perc <= 0.9]
result <- rfcv(reducedTrainingHAR[,1:52],reducedTrainingHAR[,53],cv.fold=5,mtry=function(p) max(1, floor(sqrt(p))), recursive=TRUE)
result
error.cv
result.error.cv
result$n.var
result$
result$error.cv
result$error.cv
result$predicted
prox=TRUE,allowParallel=TRUE)
modFit <- train(classe ~ ., method="rf",data=reducedTrainingHAR,trControl=trainControl(method="cv",number=5),prox=TRUE,allowParallel=TRUE)
result$error.cv
varImp(modFit)
result1 <- randomForest(reducedTrainingHAR[,1:(dim(reducedTrainingHAR)-1)],reducedTrainingHAR[,dim(reducedTrainingHAR)],cv.fold=5,mtry=function(p) max(1, floor(sqrt(p))), recursive=TRUE)
dim(reducedTrainingHAR)
dim(reducedTrainingHAR)[2]
result1 <- randomForest(reducedTrainingHAR[,1:(dim(reducedTrainingHAR)[2]-1)],reducedTrainingHAR[,dim(reducedTrainingHAR)[2]],cv.fold=5,mtry=function(p) max(1, floor(sqrt(p))), recursive=TRUE)
result1 <- randomForest(reducedTrainingHAR[,1:(dim(reducedTrainingHAR)[2]-1)],reducedTrainingHAR[,dim(reducedTrainingHAR)[2]],cv.fold=5,mtry=function(p) max(1, floor(sqrt(p))), importance=TRUE)
result1 <- randomForest(reducedTrainingHAR[,1:(dim(reducedTrainingHAR)[2]-1)],reducedTrainingHAR[,dim(reducedTrainingHAR)[2]],cv.fold=5, importance=TRUE)
varImp(result1)
varImp(result1$predicted)
varImp(result1$err.rate)
result1$err.rate
result1$predicted
result1$importance
result1$mtry
result1$ntree
result1$forest
result1$confusion
result1$importanceSD
plot(gbmImp, top = 20)
plot(result1, top = 20)
plot(result1)
plot(result1)
varImpPlot(result1,type=2)
varImpPlot(result1,type=1)
varImpPlot(result1)
varImpPlot(result1,type=1)
varImp(result1)
resu<-confusionMatrix(redreducedTestingHAR$classe, predict(result1, reducedTestingHAR))
resu<-confusionMatrix(reducedTestingHAR$classe, predict(result1, reducedTestingHAR))
resu
as.table(resu)
