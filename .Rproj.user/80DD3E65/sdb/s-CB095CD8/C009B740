{
    "contents" : "# Introduction : What is the question?\n# Data from a sample of 6 people using accelerometers on the belt, forearm, arm, and dumbell are used to understand how well\n# they are performing compared to a 'witness' group of professionnals store in A group\n# From collected observations, the aim is to buld a predictive model that will assess how well the exercise is done and rank\n# in the right group, from A to E\n#\n\n## LOAD DATA and Libraries\n\n# load relevant libraries\nlibrary(caret)\nlibrary(ISLR); library(ggplot2);\n\n# Create 1 datasets reading the CSV file\n# We will Use this dataset both for training(70%) and testing(30%) purpose.\n# \ninDatasetHAR<-read.csv(file=\"pml-training.csv\",head=TRUE,sep=\",\")\ninDatasetValidHAR<-read.csv(file=\"pml-testing.csv\",head=TRUE,sep=\",\")\n#\n#This is the data file that Velloso, E.; Bulling, A.; Gellersen, H.; \n#Ugulino, W.; Fuks, H. use in thei paper \"Qualitative Activity Recognition of \n# Weight Lifting Exercises. Proceedings of 4th International Conference in \n#Cooperation with SIGCHI (Augmented Human '13) . \n##Stuttgart, Germany: ACM SIGCHI, 2013.\n#\n##Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3mvTxcXYG\n#inDatasetRefHAR<-read.csv(file=\"dataset-har.csv\",head=TRUE,sep=\";\")\n#\n#\n#\n\ninTrainTest <- createDataPartition(y=inDatasetHAR$classe,p=0.7, list=FALSE)\n#70% of data for training and tests\n#Now Split in training and testing dataset (70% 30%)\ntrainingHAR<-inDatasetHAR[inTrainTest,]\ntestingHAR<-inDatasetHAR[-inTrainTest,]\n\n##\n## DATA ANALYSIS\n##\n#\n# First 7 columns of the datasets can be skipped as they are not relevant for the analysis (name, window, ID...)\n#\nd<-dim(trainingHAR)\ntrainingHAR<-trainingHAR[,8:d[2]]\ntestingHAR<-testingHAR[,8:d[2]]\n#\n# Analysis of training dataset : a lot of variable with \"MISSING values\", correlated and without variance\n# we can consider these as \"poor\" predictors\n#\n\n#\n#\n# Eliminates zero Variance predictors..\nnsv<-nearZeroVar(trainingHAR)\ntrainingHAR<- trainingHAR[, -nsv]\ntestingHAR<-testingHAR[,-nsv]\n##\n## Then eliminates predictors with imprtant percentage of missing values (>90%)\n##\n##\nna_count <-sapply(trainingHAR, function(y) sum(length(which(is.na(y)))))\nna_perc=na_count/dim(trainingHAR)\nreducedTrainingHAR<-trainingHAR[, na_perc <= 0.9]\nreducedTestingHAR<-testingHAR[, na_perc <= 0.9]\n#\n# So 53 selected Predictors of 160 that we will use for building the prediction model  \n#\n\n\n\n\n\n#\n# The Algorythm\n#\n#Random Forest used with cross validation seems to be a good approach, because the class of alghorithm fit\n# well this kind of classification problem, bootstrap and cross validation are easy to use.\n# We can estimate how\n# the number of predictors will influence the error of the model using the rfcv function in caret\n# set seed value and parallel options\nset.seed(125)\ndoMC::registerDoMC(cores=4)\nlibrary(MASS)\nlibrary(randomForest)\nlibrary(class)\n\n##FitModel0 <- rfcv(reducedTrainingHAR[,1:(dim(reducedTrainingHAR)[2]-1)],reducedTrainingHAR[,dim(reducedTrainingHAR)[2]],cv.fold=5,mtry=function(p) max(1, floor(sqrt(p))), recursive=TRUE)\n#\n# So the model will work fine with 26 out of the 52 predictors. the varimp function will \n# tell us which are these predictors\n# Alternatively, we can use this\n#FitModel <- randomForest(reducedTrainingHAR[,1:(dim(reducedTrainingHAR)[2]-1)],reducedTrainingHAR[,dim(reducedTrainingHAR)[2]],cv.fold=5, importance=TRUE)\nFitModel2 <- train(classe ~ ., method=\"rf\",data=reducedTrainingHAR,trControl=trainControl(method=\"cv\",number=5),prox=TRUE,importance=TRUE,allowParallel=TRUE)\nplot(FitModel2)\nplot(FitModel)\nplot(FitModel$importance)\nvarImpPlot(FitModel2)\n\n\n\nresu<-confusionMatrix(reducedTestingHAR$classe, predict(FitModel2, reducedTestingHAR))\nresu\nz<-as.table(resu)\ncolnames(z) = c(\"A\",\"B\",\"C\",\"D\",\"E\")\nrownames(z)=colnames(z)\nimage(z[,ncol(z):1], axes=FALSE)\nheatmap(t(z)[ncol(z):1,], Rowv=NA,Colv=NA, col = heat.colors(256))\noutdata20<-inDatasetValidHAR[,8:d[2]]\noutdata20<-outdata20[,-nsv]\noutdata20<-outdata20[, na_perc <= 0.9]\npredict20=predict(FitModel,outdata20)\npredict20\n\n\n\n\n\n\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\npml_write_files(answer)\n",
    "created" : 1443262617769.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3814684451",
    "id" : "C009B740",
    "lastKnownWriteTime" : 1443388858,
    "path" : "~/Documents/PML/AssignmentPML2809/Assignment-LupoPML.R",
    "project_path" : "Assignment-LupoPML.R",
    "properties" : {
        "notebook_format" : "html_document",
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}